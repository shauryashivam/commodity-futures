{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Metal Options.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "At0qq6bzsVVk"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9HwTbblmbfo"
      },
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas.plotting import lag_plot\n",
        "from pandas.plotting import autocorrelation_plot\n",
        "from matplotlib import pyplot\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import math as math\n",
        "from scipy.stats import boxcox\n",
        "from random import randrange\n",
        "from random import seed\n",
        "from random import random\n",
        "from random import gauss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66tOYdNmsiDZ"
      },
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/shauryashivam/commodity-futures/main/Dataset/Gold5.csv?token=AMF2Z3LBLLFT62EDL6NOAGDARINHK\",header=0, index_col=0, parse_dates=True,\n",
        "squeeze=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJDwoCmUn_Qt"
      },
      "source": [
        "df.drop(columns=['Open','High','Low','Adj Close','Volume'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NT7e0NmstC-"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T0ysN1wnH1s"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRnvAC7zpZyb"
      },
      "source": [
        "# Single Lag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwfsXTh_nZB9"
      },
      "source": [
        "var = pd.DataFrame(df.values)\n",
        "dataframe = pd.concat([var.shift(1), var], axis=1)\n",
        "dataframe.columns = ['t', 't+1']\n",
        "print(dataframe.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu5LDhvCpY7W"
      },
      "source": [
        "var = pd.DataFrame(df.values)\n",
        "dataframe = pd.concat([var.shift(3), var.shift(2), var.shift(1), var], axis=1)\n",
        "dataframe.columns = ['t-2', 't-1', 't', 't+1']\n",
        "print(dataframe.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rL8fCiCbpo6H"
      },
      "source": [
        "var = pd.DataFrame(df.values)\n",
        "shifted = var.shift(1)\n",
        "window = shifted.rolling(window=2)\n",
        "means = window.mean()\n",
        "dataframe = pd.concat([means, var], axis=1)\n",
        "dataframe.columns = ['mean(t-1,t)', 't+1']\n",
        "print(dataframe.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puv-foOxpuIK"
      },
      "source": [
        "var = pd.DataFrame(df.values)\n",
        "window = var.expanding()\n",
        "dataframe = pd.concat([window.min(), window.mean(), window.max(), var.shift(-1)], axis=1)\n",
        "dataframe.columns = ['min', 'mean', 'max', 't+1']\n",
        "print(dataframe.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhzI7lOvp5LE"
      },
      "source": [
        "dataframe = pd.DataFrame()\n",
        "dataframe['month'] = [df.index[i].month for i in range(len(df))]\n",
        "dataframe['day'] = [df.index[i].day for i in range(len(df))]\n",
        "dataframe['Close'] = [df['Close'] for i in range(len(df))]\n",
        "print(dataframe.head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RoTbcFLqh4v"
      },
      "source": [
        "df.plot(figsize=(15,5))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AEniQF7qu1U"
      },
      "source": [
        "import seaborn as sns\n",
        "sns.distplot(df, hist=True, kde=True,\n",
        "             bins=20,              \n",
        "             color = 'blue', \n",
        "             hist_kws={'edgecolor':'black'},\n",
        "             kde_kws={'linewidth': 2})\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BohYt_7rFix"
      },
      "source": [
        "df.head(\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jsfBPHXq6Y5"
      },
      "source": [
        "groups = df.groupby(pd.Grouper(freq='A'))\n",
        "years = pd.DataFrame()\n",
        "for name, group in groups:\n",
        "    years[name.year] = group.values\n",
        "years.boxplot(figsize=(15,5))\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFDl9Yn7rVhG"
      },
      "source": [
        "lag_plot(df)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHaHVUSJrf-U"
      },
      "source": [
        "values = pd.DataFrame(df.values)\n",
        "lags = 8\n",
        "columns = [values]\n",
        "for i in range(1,(lags + 1)):\n",
        "    columns.append(values.shift(i))\n",
        "dataframe = pd.concat(columns, axis=1)\n",
        "columns = ['t']\n",
        "for i in range(1,(lags + 1)):\n",
        "    columns.append('t-' + str(i))\n",
        "dataframe.columns = columns\n",
        "pyplot.figure(1,figsize=(15,7))\n",
        "for i in range(1,(lags + 1)):\n",
        "    ax = pyplot.subplot(240 + i)\n",
        "    ax.set_title('t vs t-' + str(i))\n",
        "    pyplot.scatter(x=dataframe['t'].values, y=dataframe['t-'+str(i)].values)\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfwyld8rrrJE"
      },
      "source": [
        "autocorrelation_plot(df)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P86BBu3mTslN"
      },
      "source": [
        "df=df.fillna(df.mean())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7a1b8w0r2Ud"
      },
      "source": [
        "upsampled = df.resample('D').mean()\n",
        "interpolated = upsampled.interpolate(method='quadratic')\n",
        "interpolated.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjLEAgU9S5L_"
      },
      "source": [
        "pip install mxnet\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aPQmaCWSyaJ"
      },
      "source": [
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from mxnet import nd, autograd, gluon\n",
        "from mxnet.gluon import nn, rnn\n",
        "import mxnet as mx\n",
        "import datetime\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "import math\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BRhGbzYwRok"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFpydnZ7xtT_"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "...     X, y, test_size=0.15, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1LvO28m6sVZ"
      },
      "source": [
        "model = tf.keras.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iK92lhND6vFs"
      },
      "source": [
        "model.add(tf.keras.layers.Conv1D(kernel_size=64,filters=3*3,strides=1,activation=\"relu\"))\n",
        "model.add(tf.keras.layers.MaxPooling1D(pool_size=2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYkndc7c7Qhc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmrVhdTlMxhx"
      },
      "source": [
        "# BUILDING MODEL \n",
        "\n",
        "## LSTM-GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiTjga9OMxE_"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.GRU(5,activation = 'relu', input_shape=(1,1)))\n",
        "model.add(Dense(100,activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mse',optimizer='adam',metrics=['mae'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k91RWv524HEm"
      },
      "source": [
        "## CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dclBL5zJ4hnl"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "from functools import reduce\n",
        "import h5py\n",
        "from numpy import newaxis\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers import Convolution1D, MaxPooling1D, Flatten,  Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAvMqnWR4Gjo"
      },
      "source": [
        "look_back = 7\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Convolution1D(input_shape = (look_back,1), \n",
        "                        nb_filter=64,\n",
        "                        filter_length=2,\n",
        "                        border_mode='valid',\n",
        "                        activation='relu',\n",
        "                        subsample_length=1)) \n",
        "model.add(MaxPooling1D(pool_length=2)) \n",
        "\n",
        "model.add(Convolution1D(input_shape = (look_back,1),\n",
        "                        nb_filter=64,\n",
        "                        filter_length=2,\n",
        "                        border_mode='valid',\n",
        "                        activation='relu',\n",
        "                        subsample_length=1))\n",
        "model.add(MaxPooling1D(pool_length=2))\n",
        "\n",
        "model.add(Dropout(0.25)) \n",
        "model.add(Flatten()) \n",
        "\n",
        "model.add(Dense(250)) \n",
        "model.add(Dropout(0.25))\n",
        "model.add(Activation('relu')) # ReLU : y = max(0,x)\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('linear')) # Linear : y = x\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
        "# training the train data with n epoch\n",
        "model.fit(np.atleast_3d(np.array(train_x)),\n",
        "          train_y,\n",
        "          epochs=100,\n",
        "          batch_size=80, verbose=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlBy9yDpMoiU"
      },
      "source": [
        "# Make prediction and specify on the line chart\n",
        "predictors = ['Dollar']\n",
        "df['Pred'] = df.loc[df.index[0], 'Dollar']\n",
        "for i in range(len(df.index)):\n",
        "    if i < look_back:\n",
        "        continue\n",
        "    a = None\n",
        "    for c in predictors:\n",
        "        b = df.loc[df.index[i-look_back:i], c].as_matrix()\n",
        "        if a is None:\n",
        "            a = b\n",
        "        else:\n",
        "            a = np.append(a,b)\n",
        "        a = a\n",
        "    y = model.predict(a.reshape(1,look_back*len(predictors),1)) \n",
        "    df.loc[df.index[i], 'Pred']=y[0][0]\n",
        "\n",
        "df.loc[:, 'Dollar'] = sc.inverse_transform(df.loc[:, 'Dollar']) \n",
        "df.loc[:, 'Pred'] = sc.inverse_transform(df.loc[:, 'Pred'])\n",
        "\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mape = (sum(np.abs((y_true - y_pred) / y_true)) / n) * 100\n",
        "    return mape\n",
        "\n",
        "# present the line chart and some parameters like MSE, which reflects the accuracy of the model in sample or out sample\n",
        "plt.plot(df.Dollar ,'b', label = 'Price')\n",
        "plt.plot(df.loc[df.index < pd.to_datetime('2010-01-01'),'Pred'], 'r', label = 'Insample Prediction')\n",
        "plt.plot(df.loc[df.index >= pd.to_datetime('2010-01-01'),'Pred'], 'g', label = 'Outsample Prediction')\n",
        "#print('%e'%mean_squared_error(df.loc[df.index < pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index < pd.to_datetime('2010-01-01'),'Pred']))\n",
        "print('The RMSE is ','%e'%sqrt(mean_squared_error(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'])))\n",
        "print('The RMAE is ','%e'%sqrt(mean_absolute_error(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'])))\n",
        "print('The MAPE is ','%e'%mape(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred']))\n",
        "\n",
        "#plt.legend()\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJQ9bYFm4lJI"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsj8wsum4bag"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "from functools import reduce\n",
        "import h5py\n",
        "from numpy import newaxis\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers import Convolution1D, MaxPooling1D, Flatten,  Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQqKOuMh4sEx"
      },
      "source": [
        "look_back = 7\n",
        "sc = StandardScaler() # 标准化数据\n",
        "df.loc[:, 'Dollar'] = sc.fit_transform(df.Dollar.values.reshape(-1,1)) # fit.transform()先拟合数据，再标准化\n",
        "print(df.loc[:, 'Dollar'])\n",
        "\n",
        "# Create training data\n",
        "#train_df = df.loc[df.index < pd.to_datetime('2010-01-01')]\n",
        "train_df = df.loc[df.index < df.index[int(len(df.index)*0.8)]]\n",
        "train_x, train_y = create_dataset(train_df, look_back=look_back)\n",
        "\n",
        "# Construct the whole LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(input_shape = (1,), input_dim=1, output_dim=6, return_sequences=True))\n",
        "model.add(LSTM(input_shape = (1,), input_dim=1, output_dim=6, return_sequences=False))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('linear'))\n",
        "model.compile(loss=\"mse\", optimizer=\"rmsprop\")\n",
        "# training the train data with n epoch\n",
        "model.fit(np.atleast_3d(np.array(train_x)),\n",
        "          train_y,\n",
        "          epochs=100,\n",
        "          batch_size=80, verbose=1, shuffle=False)\n",
        "\n",
        "# Make prediction and specify on the line chart\n",
        "predictors = ['Dollar']\n",
        "df['Pred'] = df.loc[df.index[0], 'Dollar']\n",
        "for i in range(len(df.index)):\n",
        "    if i < look_back:\n",
        "        continue\n",
        "    a = None\n",
        "    for c in predictors:\n",
        "        b = df.loc[df.index[i-look_back:i], c].as_matrix()\n",
        "        if a is None:\n",
        "            a = b\n",
        "        else:\n",
        "            a = np.append(a,b)\n",
        "        a = a\n",
        "    y = model.predict(a.reshape(1,look_back*len(predictors),1)) # 制作测试数据并把其制成矩阵，然后将其放入已经训练完的模型中。此处用的测试数据是所有数据\n",
        "    df.loc[df.index[i], 'Pred']=y[0][0]\n",
        "\n",
        "df.loc[:, 'Dollar'] = sc.inverse_transform(df.loc[:, 'Dollar']) #将标准化后是数据转换为原始数据\n",
        "df.loc[:, 'Pred'] = sc.inverse_transform(df.loc[:, 'Pred'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyUhMSn841FM"
      },
      "source": [
        "def mape(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mape = sum(np.abs((y_true - y_pred) / y_true)) / n * 100\n",
        "    return mape\n",
        "\n",
        "# present the line chart and some parameters like MSE, which reflects the accuracy of the model in sample or out sample\n",
        "plt.plot(df.Dollar ,'b', label = 'Price')\n",
        "plt.plot(df.loc[df.index < pd.to_datetime('2010-01-01'),'Pred'], 'r', label = 'Insample Prediction')\n",
        "plt.plot(df.loc[df.index >= pd.to_datetime('2010-01-01'),'Pred'], 'g', label = 'Outsample Prediction')\n",
        "#print('%e'%mean_squared_error(df.loc[df.index < pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index < pd.to_datetime('2010-01-01'),'Pred']))\n",
        "#print('The RMSE is ','%e'%sqrt(mean_squared_error(df.loc[df.index >= pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index >= pd.to_datetime('2010-01-01'),'Pred'])))\n",
        "#print('The RMAE is ','%e'%sqrt(mean_absolute_error(df.loc[df.index >= pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index >= pd.to_datetime('2010-01-01'),'Pred'])))\n",
        "#print('The MAPE is ','%e'%mape(df.loc[df.index >= pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index >= pd.to_datetime('2010-01-01'),'Pred']))\n",
        "print('The RMSE is ','%e'%sqrt(mean_squared_error(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'])))\n",
        "print('The RMAE is ','%e'%sqrt(mean_absolute_error(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'])))\n",
        "print('The MAPE is ','%e'%mape(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred']))\n",
        "\n",
        "#plt.legend()\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qv14mHw43sA"
      },
      "source": [
        "## LSTM-CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svJ0irux43Sa"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "from functools import reduce\n",
        "import h5py\n",
        "from numpy import newaxis\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers import Convolution1D, MaxPooling1D, Flatten,  Embedding\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFoApPWG4-qK"
      },
      "source": [
        "look_back = 7\n",
        "sc = StandardScaler()\n",
        "df.loc[:, 'Dollar'] = sc.fit_transform(df.Dollar.values.reshape(-1,1)) # fit.transform()\n",
        "print(df.loc[:, 'Dollar'])\n",
        "\n",
        "# Create training data\n",
        "#train_df = df.loc[df.index < pd.to_datetime('2010-01-01')]\n",
        "train_df = df.loc[df.index < df.index[int(len(df.index)*0.8)]]\n",
        "train_x, train_y = create_dataset(train_df, look_back=look_back)\n",
        "\n",
        "# Construct the whole LSTM + CNN\n",
        "model = Sequential()\n",
        "# LSTM\n",
        "model.add(LSTM(input_shape = (look_back,1), input_dim=1, output_dim=6, return_sequences=True))\n",
        "#model.add(LSTM(input_shape = (look_back,1), input_dim=1, output_dim=6, return_sequences=True))\n",
        "#model.add(Dense(1))\n",
        "#model.add(Activation('relu')) # ReLU : y = max(0,x)\n",
        "# CNN\n",
        "model.add(Convolution1D(input_shape = (look_back,1),\n",
        "                        nb_filter=64,# 128\n",
        "                        filter_length=2,\n",
        "                        border_mode='valid',\n",
        "                        activation='relu',\n",
        "                        subsample_length=1))\n",
        "#model.add(MaxPooling1D(pool_length=2)) \n",
        "\n",
        "'''model.add(Convolution1D(input_shape = (look_back,1),\n",
        "                        nb_filter=64,\n",
        "                        filter_length=2,\n",
        "                        border_mode='valid',\n",
        "                        activation='relu',\n",
        "                        subsample_length=1))'''\n",
        "model.add(MaxPooling1D(pool_length=2))\n",
        "\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Activation('relu')) # ReLU : y = max(0,x)\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('linear')) # Linear : y = x\n",
        "\n",
        "# Print whole structure of the model\n",
        "print(model.summary())\n",
        "\n",
        "# training the train data with n epoch\n",
        "model.compile(loss=\"mse\", optimizer=\"rmsprop\") # adam\n",
        "model.fit(np.atleast_3d(np.array(train_x)),\n",
        "          np.atleast_3d(train_y),\n",
        "          epochs=100,\n",
        "          batch_size=80, verbose=1, shuffle=False)\n",
        "\n",
        "# Make prediction and specify on the line chart\n",
        "predictors = ['Dollar']\n",
        "df['Pred'] = df.loc[df.index[0], 'Dollar']\n",
        "for i in range(len(df.index)):\n",
        "    if i < look_back:\n",
        "        continue\n",
        "    a = None\n",
        "    for c in predictors:\n",
        "        b = df.loc[df.index[i-look_back:i], c].as_matrix()\n",
        "        if a is None:\n",
        "            a = b\n",
        "        else:\n",
        "            a = np.append(a,b)\n",
        "        a = a\n",
        "    y = model.predict(a.reshape(1,look_back*len(predictors),1)) \n",
        "    df.loc[df.index[i], 'Pred']=y[0][0]\n",
        "\n",
        "df.loc[:, 'Dollar'] = sc.inverse_transform(df.loc[:, 'Dollar']) \n",
        "df.loc[:, 'Pred'] = sc.inverse_transform(df.loc[:, 'Pred'])\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVyp6GeY5P5T"
      },
      "source": [
        "def mape(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mape = sum(np.abs((y_true - y_pred) / y_true)) / n * 100\n",
        "    return mape\n",
        "\n",
        "# present the line chart and some parameters like MSE, which reflects the accuracy of the model in sample or out sample\n",
        "#plt.plot(df.Dollar ,'b', label = 'Price')\n",
        "#plt.plot(df.loc[df.index < pd.to_datetime('2010-01-01'),'Pred'], 'r', label = 'Insample Prediction')\n",
        "#plt.plot(df.loc[df.index >= pd.to_datetime('2010-01-01'),'Pred'], 'g', label = 'Outsample Prediction')\n",
        "#print('%e'%mean_squared_error(df.loc[df.index < pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index < pd.to_datetime('2010-01-01'),'Pred']))\n",
        "#print('%e'%mean_squared_error(df.loc[df.index >= pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index >= pd.to_datetime('2010-01-01'),'Pred']))\n",
        "print('The RMSE is ','%e'%sqrt(mean_squared_error(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'])))\n",
        "print('The RMAE is ','%e'%sqrt(mean_absolute_error(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'])))\n",
        "print('The MAPE is ','%e'%mape(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred']))\n",
        "\n",
        "#plt.legend()\n",
        "#plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9ZlHyST5TT7"
      },
      "source": [
        "## LSTM CNN Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aciFxnch5no_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "0a2d9138-4a06-4002-ff80-2ded11367db2"
      },
      "source": [
        "import os\n",
        "import time\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import operator\n",
        "from functools import reduce\n",
        "import h5py\n",
        "from numpy import newaxis\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from keras.layers import Convolution1D, MaxPooling1D, Flatten,  Embedding,Bidirectional\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, merge\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from math import sqrt\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-0fad80145fd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecurrent\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_self_attention\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSeqSelfAttention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_self_attention'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ajHAERIGnNl",
        "outputId": "6c2c3684-83df-40bb-a784-f8014ed29100"
      },
      "source": [
        "pip install keras-attention\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-attention\n",
            "  Downloading https://files.pythonhosted.org/packages/9a/e9/1373dff1b2dd7cb45208d224c84d7a2bddcf0519f01d98f07d8ce15dc4be/keras_attention-1.0.0-py3-none-any.whl\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-attention) (2.4.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras->keras-attention) (2.10.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras->keras-attention) (3.13)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras->keras-attention) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras->keras-attention) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras->keras-attention) (1.15.0)\n",
            "Installing collected packages: keras-attention\n",
            "Successfully installed keras-attention-1.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F_029-65SBZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "5dac8164-9c16-4be2-b700-18a14267cfde"
      },
      "source": [
        "look_back = 7 # 10, 13\n",
        "sc = StandardScaler()  \n",
        "df.loc[:, 'Dollar'] = sc.fit_transform(df.Dollar.values.reshape(-1,1)) # fit.transform()\n",
        "print(df.loc[:, 'Dollar'])\n",
        "\n",
        "# Create training data\n",
        "#train_df = df.loc[df.index < pd.to_datetime('2010-01-01')]\n",
        "train_df = df.loc[df.index < df.index[int(len(df.index)*0.8)]]\n",
        "train_x, train_y = create_dataset(train_df, look_back=look_back)\n",
        "\n",
        "# Construct the whole LSTM + CNN\n",
        "model = Sequential()\n",
        "# LSTM\n",
        "model.add(LSTM(input_shape = (look_back, 1), input_dim=1, output_dim=6,  return_sequences=True))\n",
        "\n",
        "#model.add(LSTM(input_shape = (look_back,1), input_dim=1, output_dim=6, return_sequences=True))\n",
        "#model.add(Dense(1))\n",
        "#model.add(Activation('relu')) # ReLU : y = max(0,x)\n",
        "\n",
        "# Attention Mechanism\n",
        "model.add(SeqSelfAttention(attention_activation='sigmoid', name='Attention'))\n",
        "\n",
        "# CNN\n",
        "model.add(Convolution1D(input_shape = (look_back,1),\n",
        "                        nb_filter=64,# 32,128\n",
        "                        filter_length=2,\n",
        "                        border_mode='valid',\n",
        "                        activation='relu',\n",
        "                        subsample_length=1))\n",
        "#model.add(MaxPooling1D(pool_length=2)) \n",
        "\n",
        "'''model.add(Convolution1D(input_shape = (look_back,1),\n",
        "                        nb_filter=64,\n",
        "                        filter_length=2,\n",
        "                        border_mode='valid',\n",
        "                        activation='relu',\n",
        "                        subsample_length=1))'''\n",
        "model.add(MaxPooling1D(pool_length=2))\n",
        "\n",
        "#model.add(Dropout(0.25))\n",
        "\n",
        "#model.add(Dense(250)) \n",
        "model.add(Dropout(0.25))\n",
        "model.add(Activation('relu')) # ReLU : y = max(0,x)\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('linear')) # Linear : y = x\n",
        "\n",
        "# Print whole structure of the model\n",
        "print(model.summary())\n",
        "\n",
        "# training the train data with n epoch\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\") # adam, rmsprop\n",
        "result = model.fit(np.atleast_3d(np.array(train_x)),\n",
        "          np.atleast_3d(train_y),\n",
        "          epochs=100,\n",
        "          batch_size=80, verbose=1, shuffle=False)\n",
        "\n",
        "\n",
        "with open('data_lstm_attention_cnn_palladium.txt','w') as f:\n",
        "    f.write(str(result.history))\n",
        "\n",
        "model.save('lstm_attention_cnn_palladium.h5')\n",
        "\n",
        "\n",
        "# Make prediction and specify on the line chart\n",
        "predictors = ['Dollar']\n",
        "df['Pred'] = df.loc[df.index[0], 'Dollar']\n",
        "for i in range(len(df.index)):\n",
        "    if i < look_back:\n",
        "        continue\n",
        "    a = None\n",
        "    for c in predictors:\n",
        "        b = df.loc[df.index[i-look_back:i], c].as_matrix()\n",
        "        if a is None:\n",
        "            a = b\n",
        "        else:\n",
        "            a = np.append(a,b)\n",
        "        a = a\n",
        "    y = model.predict(a.reshape(1,look_back*len(predictors),1)) \n",
        "    df.loc[df.index[i], 'Pred']=y[0][0]\n",
        "\n",
        "df.loc[:, 'Dollar'] = sc.inverse_transform(df.loc[:, 'Dollar']) \n",
        "df.loc[:, 'Pred'] = sc.inverse_transform(df.loc[:, 'Pred'])\n",
        "\n",
        "def mape(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mape = sum(np.abs((y_true - y_pred) / y_true)) / n * 100\n",
        "    return mape\n",
        "\n",
        "# present the line chart and some parameters like MSE, which reflects the accuracy of the model in sample or out sample\n",
        "plt.grid(ls='--')\n",
        "plt.plot(df.loc[df.index < df.index[int(len(df.index)*0.8)], 'Pred'], 'orange', label = 'Insample Prediction')\n",
        "plt.plot(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'], 'g', label = 'Outsample Prediction')\n",
        "plt.plot(df.Dollar ,'b', label = 'Price')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('USD/oz')\n",
        "#print('%e'%mean_squared_error(df.loc[df.index < pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index < pd.to_datetime('2010-01-01'),'Pred']))\n",
        "#print('%e'%mean_squared_error(df.loc[df.index >= pd.to_datetime('2010-01-01'),'Dollar'],df.loc[df.index >= pd.to_datetime('2010-01-01'),'Pred']))\n",
        "print('The RMSE is ','%e'%sqrt(mean_squared_error(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'])))\n",
        "print('The RMAE is ','%e'%sqrt(mean_absolute_error(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred'])))\n",
        "print('The MAPE is ','%e'%mape(df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Dollar'], df.loc[df.index >= df.index[int(len(df.index)*0.8)], 'Pred']))\n",
        "\n",
        "plt.legend()\n",
        "plt.savefig(\"lstm_attention_cnn_palladium.eps\", format='eps', dpi=1000)\n",
        "plt.show()\n",
        "'''\n",
        "# sketch loss\n",
        "#plt.cla() # clear the axis\n",
        "plt.grid(ls='--')\n",
        "plt.plot(result.epoch,result.history['loss'],label='LOSS',c='r',lw=3)\n",
        "#plt.scatter(result.epoch,result.history['loss'],s=15,c='r')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right', frameon=True, edgecolor='black')\n",
        "plt.savefig(\"LC_loss.eps\", format='eps', dpi=1000)\n",
        "plt. close(0)\n",
        "'''"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1605f437cab0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlook_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m \u001b[0;31m# 10, 13\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dollar'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDollar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fit.transform()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Dollar'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'StandardScaler' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOuaz6bO5whG"
      },
      "source": [
        "## ARIMA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INVHt_UN5wMM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}